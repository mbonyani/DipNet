{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install tensorflow_addons==0.11.2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib\n","import pandas as pnd\n","from tqdm import tqdm\n","import sys\n","import math\n","import os\n","import zipfile\n","import six\n","import warnings\n","import random\n","import gc\n","import six\n","from math import ceil\n","from sklearn.model_selection import KFold, StratifiedKFold,train_test_split\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","from keras.metrics import top_k_categorical_accuracy\n","\n","\n","import cv2\n","import imgaug as ia\n","from imgaug import augmenters as iaa\n","# from moviepy.editor import VideoFileClip\n","from PIL import Image\n","\n","from tensorflow.keras.utils import to_categorical\n","\n","from scipy.io import loadmat\n","import keras.backend as K\n","from keras.engine.topology import get_source_inputs\n","from keras.layers import Activation\n","from keras.layers import AveragePooling3D\n","from keras.layers import BatchNormalization\n","from keras.layers import Conv3D\n","from keras.layers import Conv3DTranspose\n","from keras.layers import Dense\n","from keras.layers import Dropout,Flatten\n","from keras.layers import GlobalAveragePooling3D\n","from keras.layers import GlobalMaxPooling3D\n","from keras.layers import Input\n","from keras.layers import MaxPooling3D\n","from keras.layers import Reshape\n","from keras.layers import UpSampling3D\n","from keras.layers import Concatenate\n","from tensorflow.keras.models import Model,load_model\n","from keras.regularizers import l2\n","!pip install git+https://www.github.com/keras-team/keras-contrib.git\n","from keras_contrib.layers import SubPixelUpscaling\n","from tensorflow.keras.callbacks import LearningRateScheduler\n","from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n","from tensorflow.keras.optimizers import SGD,Adam"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["! nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["data_road = np.load('input/brain4carsnumpy/data_road.npy') \n","data_face = np.load('input/brain4carsnumpy/data_face.npy') \n","\n","data_road_asl = np.load('input/brain4carsnumpy/data_road_asl.npy')\n","data_face_asl = np.load('input/brain4carsnumpy/data_face_asl.npy')\n","\n","labels = np.load('input/brain4carsnumpy/labels_road.npy')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.utils import shuffle\n","data_road , data_road_asl ,data_face , data_face_asl,labels = shuffle(data_road , data_road_asl ,data_face , data_face_asl,labels,random_state=0 )"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def data_augmentation_tempen1(inputs,inputs1,inputs2,inputs3,y):\n","    trans_range=4\n","    temp_lst = []\n","    temp_lst1 = []\n","    temp_lst2 = []\n","    temp_lst3 = []\n","    yy = []\n","    # p0 = np.random.randint(-trans_range, trans_range + 1) + trans_range\n","    # p1 = np.random.randint(-trans_range, trans_range + 1) + trans_range\n","\n","\n","    if 1:\n","      if y==1:\n","        yy=3\n","      if y==3:\n","        yy=1\n","      if y==2:\n","        yy=4\n","      if y==4:\n","        yy=2\n","      for img in inputs:\n","\n","          img = img[:, ::-1, :]\n","          p0 = np.random.randint(-trans_range, trans_range + 1) + trans_range\n","          p1 = np.random.randint(-trans_range, trans_range + 1) + trans_range\n","          img1 = img[p0:p0 + 128, p1:p1 + 128, :]\n","          img = cv2.resize(img1,(128,128))\n","          temp_lst.append(img)\n","      for img in inputs1:\n","\n","          img = img[:, ::-1, :]\n","          p0 = np.random.randint(-trans_range, trans_range + 1) + trans_range\n","          p1 = np.random.randint(-trans_range, trans_range + 1) + trans_range \n","          img1 = img[p0:p0 + 128, p1:p1 + 128, :]\n","          img = cv2.resize(img1,(128,128))\n","          temp_lst1.append(img)\n","      for img in inputs2:\n","\n","          img = img[:, ::-1, :]\n","          p0 = np.random.randint(-trans_range, trans_range + 1) + trans_range\n","          p1 = np.random.randint(-trans_range, trans_range + 1) + trans_range\n","          img1 = img[p0:p0 + 128, p1:p1 + 128, :]\n","          img = cv2.resize(img1,(128,128))\n","          temp_lst2.append(img)\n","      for img in inputs3:\n","\n","          img = img[:, ::-1, :]\n","          p0 = np.random.randint(-trans_range, trans_range + 1) + trans_range\n","          p1 = np.random.randint(-trans_range, trans_range + 1) + trans_range\n","          img1 = img[p0:p0 + 128, p1:p1 + 128, :]\n","          img = cv2.resize(img1,(128,128))\n","          temp_lst3.append(img)\n","      return np.array(temp_lst),np.array(temp_lst1),np.array(temp_lst2),np.array(temp_lst3),yy\n","    else:\n","      return inputs , inputs1 , inputs2 , inputs3 , y\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def data_augmentation_tempen(inputs,inputs1,inputs2,inputs3,y):\n","    trans_range=4\n","    temp_lst = []\n","    temp_lst1 = []\n","    temp_lst2 = []\n","    temp_lst3 = []\n","    yy = []\n","    # p0 = np.random.randint(-trans_range, trans_range + 1) + trans_range\n","    # p1 = np.random.randint(-trans_range, trans_range + 1) + trans_range\n","\n","\n","    if np.random.uniform() > 0.5:\n","      if y==1:\n","        yy=3\n","      if y==3:\n","        yy=1\n","      if y==2:\n","        yy=4\n","      if y==4:\n","        yy=2\n","      inputs  = np.pad(inputs, ((0, 0), (trans_range, trans_range), (trans_range, trans_range), (0, 0)), 'reflect')\n","      inputs1 = np.pad(inputs1, ((0, 0), (trans_range, trans_range), (trans_range, trans_range), (0, 0)), 'reflect')\n","      inputs2 = np.pad(inputs2, ((0, 0), (trans_range, trans_range), (trans_range, trans_range), (0, 0)), 'reflect')\n","      inputs3 = np.pad(inputs3, ((0, 0), (trans_range, trans_range), (trans_range, trans_range), (0, 0)), 'reflect')\n","      for img in inputs:\n","\n","          img = img[:, ::-1, :]\n","          p0 = np.random.randint(-trans_range, trans_range + 1) + trans_range\n","          p1 = np.random.randint(-trans_range, trans_range + 1) + trans_range\n","          img1 = img[p0:p0 + 128, p1:p1 + 128, :]\n","          img = cv2.resize(img1,(128,128))\n","          temp_lst.append(img)\n","      for img in inputs1:\n","\n","          img = img[:, ::-1, :]\n","          p0 = np.random.randint(-trans_range, trans_range + 1) + trans_range\n","          p1 = np.random.randint(-trans_range, trans_range + 1) + trans_range \n","          img1 = img[p0:p0 + 128, p1:p1 + 128, :]\n","          img = cv2.resize(img1,(128,128))\n","          temp_lst1.append(img)\n","      for img in inputs2:\n","\n","          img = img[:, ::-1, :]\n","          p0 = np.random.randint(-trans_range, trans_range + 1) + trans_range\n","          p1 = np.random.randint(-trans_range, trans_range + 1) + trans_range\n","          img1 = img[p0:p0 + 128, p1:p1 + 128, :]\n","          img = cv2.resize(img1,(128,128))\n","          temp_lst2.append(img)\n","      for img in inputs3:\n","\n","          img = img[:, ::-1, :]\n","          p0 = np.random.randint(-trans_range, trans_range + 1) + trans_range\n","          p1 = np.random.randint(-trans_range, trans_range + 1) + trans_range\n","          img1 = img[p0:p0 + 128, p1:p1 + 128, :]\n","          img = cv2.resize(img1,(128,128))\n","          temp_lst3.append(img)\n","      return np.array(temp_lst),np.array(temp_lst1),np.array(temp_lst2),np.array(temp_lst3),yy\n","    else:\n","      return inputs , inputs1 , inputs2 , inputs3 , y\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def mixup_data(imgf,imgr,imgfa,imgra):\n","\n","    lmbda= np.random.beta(1., 1.) \n","    \n","    rv= np.random.permutation(30) \n","    imgf = lmbda * imgf + (1- lmbda) * imgf[rv] \n","    imgr = lmbda * imgr + (1- lmbda) * imgr[rv] \n","    imgfa= lmbda * imgfa + (1- lmbda) * imgfa[rv] \n","    imgra= lmbda * imgra + (1- lmbda) * imgra[rv] \n","\n","    # y_lmix= lmbda * y_l + (1- lmbda) * y_l[rv]\n","    \n","    return imgf,imgr,imgfa,imgra\n","\n","import tensorflow_addons as tfa\n","def augment_cutout(image):\n","  image = tf.convert_to_tensor(image)\n","  p0 = np.random.randint(0, 15)*2\n","  p1 = np.random.randint(0, 15)*2\n","  img = tfa.image.random_cutout(image, (p0,p1), constant_values = 0)\n","  \n","  return img"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from keras.layers.merge import add\n","from keras.layers.normalization import BatchNormalization\n","from keras.regularizers import l2\n","from keras import backend as K\n","\n","!pip install keras_applications==1.0.7\n","!pip install classification-models-3D\n","!pip install efficientnet-3D\n","!pip install keras-self-attention\n","!git clone https://github.com/uzaymacar/attention-mechanisms.git\n","sys.path.append('./attention-mechanisms')\n","from layers import Attention"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# use it\n","\n","import keras\n","from keras_applications.imagenet_utils import _obtain_input_shape\n","from keras_applications.imagenet_utils import preprocess_input as _preprocess_input\n","from classification_models_3D.tfkeras import Classifiers\n","from keras.layers.noise import GaussianNoise\n","from keras.models import Model\n","from keras.layers import Concatenate, Dense, LSTM, Input, concatenate\n","from keras.regularizers import l2 # L2-regularisation\n","from keras.metrics import top_k_categorical_accuracy\n","from keras_self_attention import SeqSelfAttention, SeqWeightedAttention\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras import backend as K\n","\n","\n","def _bernoulli(shape, mean):\n","    return tf.nn.relu(tf.sign(mean - tf.random.uniform(shape, minval=0, maxval=1, dtype=tf.float32)))\n","\n","\n","class DropBlock2D(tf.keras.layers.Layer):\n","    def __init__(self, keep_prob, block_size, scale=True,name=None, **kwargs):\n","        super(DropBlock2D, self).__init__(name=\"DropBlock2D\")\n","        self.keep_prob = float(keep_prob) if isinstance(keep_prob, int) else keep_prob\n","        self.block_size = int(block_size)\n","        self.names = name\n","        self.scale = tf.constant(scale, dtype=tf.bool) if isinstance(scale, bool) else scale\n","        super(DropBlock2D, self).__init__(**kwargs)\n","        \n","    def get_config(self):\n","        config = super().get_config().copy()\n","        config.update( {\"block_size\": self.block_size,\"keep_prob\": self.keep_prob,\"name\": self.names })\n","\n","        \n","        \n","        return config\n","\n","    def compute_output_shape(self, input_shape):\n","        return input_shape\n","\n","    def build(self, input_shape):\n","        assert len(input_shape) == 4\n","        _, self.h, self.w, self.channel = input_shape.as_list()\n","        # pad the mask\n","        p1 = (self.block_size - 1) // 2\n","        p0 = (self.block_size - 1) - p1\n","        self.padding = [[0, 0], [p0, p1], [p0, p1], [0, 0]]\n","        self.set_keep_prob()\n","        super(DropBlock2D, self).build(input_shape)\n","\n","    def call(self, inputs, training=None, **kwargs):\n","        def drop():\n","            mask = self._create_mask(tf.shape(inputs))\n","            output = inputs * mask\n","            output = tf.cond(self.scale,\n","                             true_fn=lambda: output *tf.cast(tf.size(mask), dtype=tf.float32)  / tf.reduce_sum(mask),\n","                             false_fn=lambda: output)\n","            return output\n","\n","        if training is None:\n","            training = K.learning_phase()\n","        output = tf.cond(tf.logical_or(tf.logical_not(training), tf.equal(self.keep_prob, 1.0)),\n","                         true_fn=lambda: inputs,\n","                         false_fn=drop)\n","        return output\n","\n","    def set_keep_prob(self, keep_prob=None):\n","        \"\"\"This method only supports Eager Execution\"\"\"\n","        if keep_prob is not None:\n","            self.keep_prob = keep_prob\n","        w, h = tf.cast(self.w, dtype=tf.float32), tf.cast(self.h, dtype=tf.float32)\n","        \n","        self.gamma = (1. - self.keep_prob) * (w * h) / (self.block_size ** 2) / \\\n","                     ((w - self.block_size + 1) * (h - self.block_size + 1))\n","\n","    def _create_mask(self, input_shape):\n","        sampling_mask_shape = tf.stack([input_shape[0],\n","                                       self.h - self.block_size + 1,\n","                                       self.w - self.block_size + 1,\n","                                       self.channel])\n","        mask = _bernoulli(sampling_mask_shape, self.gamma)\n","        mask = tf.pad(mask, self.padding)\n","        mask = tf.nn.max_pool(mask, [1, self.block_size, self.block_size, 1], [1, 1, 1, 1], 'SAME')\n","        mask = 1 - mask\n","        return mask\n","\n","\n","class DropBlock3D(tf.keras.layers.Layer):\n","    def __init__(self, keep_prob, block_size, scale=True,name=None, **kwargs):\n","        super(DropBlock3D, self).__init__(name=\"DropBlock3D\")\n","        self.keep_prob = float(keep_prob) if isinstance(keep_prob, int) else keep_prob\n","        self.block_size = int(block_size)\n","        self.scale = tf.constant(scale, dtype=tf.bool) if isinstance(scale, bool) else scale\n","        super(DropBlock3D, self).__init__(**kwargs)\n","\n","    def compute_output_shape(self, input_shape):\n","        return input_shape\n","\n","    def build(self, input_shape):\n","        assert len(input_shape) == 5\n","        _, self.d, self.h, self.w, self.channel = input_shape.as_list()\n","        # pad the mask\n","        p1 = (self.block_size - 1) // 2\n","        p0= (self.block_size - 1) - p1\n","        self.padding = [[0, 0], [p0, p1], [p0, p1], [p0, p1], [0, 0]]\n","        self.set_keep_prob()\n","        super(DropBlock3D, self).build(input_shape)\n","\n","    def call(self, inputs, training=None, **kwargs):\n","        def drop():\n","            mask = self._create_mask(tf.shape(inputs))\n","            output = inputs * mask\n","            output = tf.cond(self.scale,\n","                             true_fn=lambda: output *tf.cast(tf.size(mask), dtype=tf.float32)  / tf.reduce_sum(mask),\n","                             false_fn=lambda: output)\n","            return output\n","\n","        if training is None:\n","            training = K.learning_phase()\n","        output = tf.cond(tf.logical_or(tf.logical_not(training), tf.equal(self.keep_prob, 1.0)),\n","                         true_fn=lambda: inputs,\n","                         false_fn=drop)\n","        return output\n","\n","    def set_keep_prob(self, keep_prob=None):\n","        \"\"\"This method only supports Eager Execution\"\"\"\n","        if keep_prob is not None:\n","            self.keep_prob = keep_prob\n","        d, w, h = tf.cast(self.d, dtype=tf.float32), tf.cast(self.w, dtype=tf.float32), tf.cast(self.h, dtype=tf.float32)\n","        self.gamma = ((1. - self.keep_prob) * (d * w * h) / (self.block_size ** 3) /\n","                      ((d - self.block_size + 1) * (w - self.block_size + 1) * (h - self.block_size + 1)))\n","\n","    def _create_mask(self, input_shape):\n","        sampling_mask_shape = tf.stack([input_shape[0],\n","                                        self.d - self.block_size + 1,\n","                                        self.h - self.block_size + 1,\n","                                        self.w - self.block_size + 1,\n","                                        self.channel])\n","        mask = _bernoulli(sampling_mask_shape, self.gamma)\n","        mask = tf.pad(mask, self.padding)\n","        mask = tf.nn.max_pool3d(mask, [1, self.block_size, self.block_size, self.block_size, 1], [1, 1, 1, 1, 1], 'SAME')\n","        mask = 1 - mask\n","        return mask"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# use it\n","\n","import keras\n","\n","\n","from keras.models import Model\n","from keras.layers import Concatenate, Dense, LSTM, Input, concatenate,AveragePooling2D,TimeDistributed\n","from keras.regularizers import l2 # L2-regularisation\n","from keras.metrics import top_k_categorical_accuracy\n","from tensorflow.keras.applications.densenet import DenseNet121\n","from tensorflow.keras.applications import Xception\n","import tensorflow as tf \n","import random\n","import os\n","seed_value= 0\n","os.environ['PYTHONHASHSEED']=str(seed_value)\n","random.seed(seed_value)\n","np.random.seed(seed_value)\n","tf.random.set_seed(seed_value)\n","\n","\n","def define_model(input_shape):\n","\n","    road = Input(shape=(128, 128,3))\n","    face = Input(shape=(128, 128,3))\n","#     road_opt = Input(shape=(128, 128,3))\n","#     face_opt = Input(shape=(128, 128,3))\n","\n","    # road = Input(shape=(128, 384))\n","    road_opt = Input(shape=(128, 384))\n","    # face = Input(shape=(128, 384))\n","    face_opt = Input(shape=(128, 384))\n","\n","    # road     = Input(shape=( 384,128))\n","    # road_opt = Input(shape=( 384,128))\n","    # face     = Input(shape=( 384,128))\n","    # face_opt = Input(shape=( 384,128))\n","    # road_opt = Input(shape=(15,128, 128,3))\n","    # face_opt = Input(shape=(15,128, 128,3))\n","\n","\n","    model1 = DenseNet121(include_top=False, weights='imagenet', input_tensor=road, input_shape=None, pooling=None, classes=1000)\n","    model2 = DenseNet121(include_top=False, weights='imagenet', input_tensor=face, input_shape=None, pooling=None, classes=1000)\n","    # model3 = DenseNet121(include_top=False, weights='imagenet', input_tensor=road_opt, input_shape=None, pooling=None, classes=1000)\n","    # model4 = DenseNet121(include_top=False, weights='imagenet', input_tensor=face_opt, input_shape=None, pooling=None, classes=1000)\n","    # base1 = Inception_Inflated3d(include_top=False,weights=None,input_tensor=None,input_shape=(15, 128,128,3),dropout_prob=0.0,endpoint_logit=False,classes=12)\n","    # base2 = Inception_Inflated3d(include_top=False,weights=None,input_tensor=None,input_shape=(15, 128,128,3),dropout_prob=0.0,endpoint_logit=False,classes=12)\n","\n","    model1.trainable = True\n","    model2.trainable = True\n","    # model3.trainable = True\n","    # model4.trainable = True\n","    model1._name ='de'\n","    model2._name = 'dr'\n","    # base1._name ='dx'\n","    # base2._name = 'dc'\n","    # model3._name ='dee'\n","    # model4._name = 'dre'\n","    for layer in model2.layers:\n","      layer._name = layer.name + str(\"_2\")\n","    # for layer in base2.layers:\n","    #   layer._name = layer.name + str(\"_2\")\n","    # for layer in model3.layers:\n","    #   layer._name = layer.name + str(\"_21\")\n","    # for layer in model4.layers:\n","    #   layer._name = layer.name + str(\"_22\")\n","\n","\n","    regularizer = tf.keras.regularizers.l2(0.0001)\n","\n","    # for layer in model2.layers:\n","    #     for attr in ['kernel_regularizer']:\n","    #         if hasattr(layer, attr):\n","    #           setattr(layer, attr, regularizer)\n","    # for layer in model1.layers:\n","    #     for attr in ['kernel_regularizer']:\n","    #         if hasattr(layer, attr):\n","    #           setattr(layer, attr, regularizer)\n","    x1 = model1.get_layer(model1.layers[-1].name).output\n","    x2 = model2.get_layer(model2.layers[-1].name).output\n","    # x2 = model2(face)\n","    print(x2.shape)\n","    # x3 = model3.get_layer(model3.layers[-1].name).output\n","    # x4 = model4.get_layer(model4.layers[-1].name).output\n","    x2 = DropBlock2D(keep_prob=0.5, block_size=5)(x2,training=trainphase)\n","    x1 = DropBlock2D(keep_prob=0.5, block_size=5)(x1,training=trainphase)\n","\n","    x2 = AveragePooling2D((4,4))(x2)\n","    x1 = AveragePooling2D((4,4))(x1)\n","    # x2 = TimeDistributed(model1)(road)\n","    # x2 = TimeDistributed(model2)(face)\n","    # print(x2.shape)\n","    # x3 = AveragePooling2D((4,4))(x3)\n","    # x4 = AveragePooling2D((4,4))(x4)\n","    # print(AveragePooling2D((4,4))(x1).shape)\n","    feat = 128\n","    feat1 = 128\n","    feat2 = 512\n","    feat3 = 64\n","    numimg = 15\n","    ####### Feature Extraact From all frame input\n","    # out2 = tf.keras.layers.Embedding(256, 64, input_length=10)\n","    # out4 = tf.keras.layers.Embedding(256, 64, input_length=10)\n","    # out2 = base1(road_opt)\n","    # out4 = base2(face_opt)\n","    # road_opt = K.reshape(road_opt,(-1,128, 384))\n","    # face_opt = K.reshape(face_opt,(-1,128, 384))\n","\n","    whole_seq_output2, final_memory_state2, final_carry_state2 = tf.keras.layers.LSTM(feat, return_sequences=True, return_state=True,dropout=0.0, recurrent_dropout=0.0)(road_opt) \n","    whole_seq_output4, final_memory_state4, final_carry_state4 = tf.keras.layers.LSTM(feat, return_sequences=True, return_state=True,dropout=0.0, recurrent_dropout=0.0)(face_opt)\n","    # out2 = base1(road_opt)\n","    # out4 = base2(face_opt)\n","    # print(out2.shape)\n","    out1 = K.reshape(x1,(-1, numimg,1024))\n","    out2 = K.reshape(final_carry_state2,(-1, numimg,feat))\n","    \n","\n","#     out2 = K.reshape(whole_seq_output2,(-1, feat,numimg*feat))\n","    # out22 = K.reshape(out2,(-1,1024))\n","\n","\n","    # out2 = K.reshape(x3,(-1, numimg,1024))\n","\n","    out3 = K.reshape(x2,(-1, numimg,1024))\n","    out4 = K.reshape(final_carry_state4,(-1, numimg,feat))\n","    # out4 = K.reshape(whole_seq_output4,(-1, feat,numimg*feat))\n","    # out44 = K.reshape(out4,(-1,1024))\n","\n","\n","    # out4 = K.reshape(x4,(-1, numimg,1024))\n","    # out1 = Concatenate(axis=-2)([out1, out3])\n","\n","\n","    whole_seq_outpu1, final_memory_stat1, final_carry_stat1 = tf.keras.layers.LSTM(feat2, return_sequences=True, return_state=True,dropout=0.0)(out1)\n","    whole_seq_outpu2, final_memory_stat2, final_carry_stat2 = tf.keras.layers.LSTM(feat2, return_sequences=True, return_state=True,dropout=0.0)(out2) \n","    whole_seq_outpu3, final_memory_stat3, final_carry_stat3 = tf.keras.layers.LSTM(feat2, return_sequences=True, return_state=True,dropout=0.0)(out3)\n","    whole_seq_outpu4, final_memory_stat4, final_carry_stat4 = tf.keras.layers.LSTM(feat2, return_sequences=True, return_state=True,dropout=0.0)(out4)\n","\n","    # whole_seq_outpu1, final_memory_stat1, final_carry_stat1 = tf.keras.layers.LSTM(feat2, return_sequences=True, return_state=True,dropout=0.1)(whole_seq_outpu1)\n","    # whole_seq_outpu2, final_memory_stat2, final_carry_stat2 = tf.keras.layers.LSTM(feat1, return_sequences=True, return_state=True,dropout=0.0)(whole_seq_outpu2) \n","    # whole_seq_outpu3, final_memory_stat3, final_carry_stat3 = tf.keras.layers.LSTM(feat2, return_sequences=True, return_state=True,dropout=0.1)(whole_seq_outpu3)\n","    # whole_seq_outpu4, final_memory_stat4, final_carry_stat4 = tf.keras.layers.LSTM(feat1, return_sequences=True, return_state=True,dropout=0.0)(whole_seq_outpu4)\n","\n","\n","    # merge_model1 = SeqWeightedAttention()(whole_seq_outpu1)\n","    # merge_model2 = SeqWeightedAttention()(whole_seq_outpu2)\n","    # merge_model3 = SeqWeightedAttention()(whole_seq_outpu3)\n","    # merge_model4 = SeqWeightedAttention()(whole_seq_outpu4)\n","\n","    # out = Concatenate(axis=-1)([merge_model1, merge_model2,merge_model3,merge_model4])\n","    \n","    out = Concatenate(axis=-1)([final_carry_stat1, final_carry_stat2,final_carry_stat3,final_carry_stat4])\n","    # out1 = Concatenate(axis=-1)([final_carry_stat2,final_carry_stat4])\n","#     out = Concatenate(axis=-1)([final_carry_stat1,final_carry_stat3])\n","\n","\n","    # output =  Concatenate(axis=-1)([out1, out3])\n","\n","    merge_model = Flatten(name='flatten1')(out)\n","\n","    # merge_model1 = Flatten(name='flatten11')(output)\n","\n","    # merge_model = Dense(512, activation='relu')(merge_model)\n","    # merge_model = Dropout(0.45)(merge_model)\n","\n","    # merge_model1 = Dense(512, activation='relu')(merge_model1)\n","    # merge_model = Dropout(0.25)(merge_model)\n","\n","    # merge_model =  Concatenate(axis=-1)([merge_model, merge_model1])\n","\n","    # predictions = Dense(5,activation=\"softmax\")(merge_model)\n","\n","\n","    # merge_model = Flatten(name='flatten1')(out1)\n","\n","    # # merge_model1 = Flatten(name='flatten11')(output)\n","\n","    # merge_model = Dense(512, activation='relu')(merge_model)\n","    # # merge_model = Dropout(0.45)(merge_model)\n","\n","    # # merge_model1 = Dense(512, activation='relu')(merge_model1)\n","    # merge_model = Dropout(0.25)(merge_model)\n","\n","    # # merge_model =  Concatenate(axis=-1)([merge_model, merge_model1])\n","\n","    # predictions1 = Dense(5,activation=\"softmax\")(merge_model)\n","\n","    # if tf.keras.backend.max(predictions1,axis = 0) >tf.keras.backend.max(predictions,axis=0):#tf.keras.layers.Lambda(custom_layer, name=\"lambda_layer\")([predictions1,predictions]):\n","    #   predictions = predictions1\n","    # def custom_layer1(tensor):\n","    #   return tensor\n","    # predictions = tf.cond(tf.keras.backend.max(predictions1,axis = 0) >tf.keras.backend.max(predictions,axis=0), lambda: custom_layer1(predictions1), lambda: custom_layer1(predictions))\n","\n","\n","\n","    \n","    model = Model(inputs= [road,road_opt,face,face_opt], outputs=[merge_model],name ='kfj')\n","\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","def define_modelfc(input_shape):\n","    road = Input(shape=(2048,))\n","    merge_model = Dense(512, activation='relu')(road)\n","    merge_model = Dropout(0.45)(merge_model)\n","\n","    predictions = Dense(5,activation=\"softmax\")(road)    \n","    model = Model(inputs= [road], outputs=[predictions],name ='fc')\n","\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# @tf.function(experimental_relax_shapes=True)\n","def train_step(images_a,images_b,sample_labels,epoch):\n","\n","    # ratio = lambda_0 * (epoch / 300)\n","    ratio = .25 * (epoch / 160)\n","\n","    with tf.GradientTape() as STtape:\n","\n","        features = modela(images_a, training=True)\n","        y = modelb(features, training=True)\n","        isda.estimator.update_CV(np.array(features), np.argmax(sample_labels,axis=1))\n","        isda_aug_y = isda.isda_aug(modelb, features, y, np.argmax(sample_labels,axis=1), isda.estimator.CoVariance, ratio)\n","        supervised_lossb = CCLoss1(sample_labels,isda_aug_y)\n","\n","\n","    # isda.estimator.update_CV(np.array(features), np.argmax(sample_labels,axis=1))\n","\n","    # with tf.GradientTape() as STtape1:\n","\n","        \n","    #     y = modelb(features, training=True)\n","    #     isda_aug_y = isda.isda_aug(modelb, features, y, np.argmax(sample_labels,axis=1), isda.estimator.CoVariance, ratio)\n","\n","       \n","    #     supervised_lossb = CCLoss1(sample_labels,isda_aug_y)\n","        \n","\n","    variables = modela.trainable_variables + modelb.trainable_variables\n","\n","    gradsa = STtape.gradient(supervised_lossb, variables)\n","    optimizer.apply_gradients(zip(gradsa,variables))\n","\n","    # grads = STtape.gradient(supervised_lossb, modelb.trainable_variables)\n","    # optimizer.apply_gradients(zip(grads, modelb.trainable_variables))\n","\n","\n","    return  supervised_lossb\n","def evaluate():\n","    loss = 0\n","\n","    st_accb = tf.keras.metrics.Accuracy()\n","\n","\n","    for i in range(num_train_data, num_test, batch_size):\n","       \n","        x_batch = []\n","        x_batch1 = []\n","        x_batch3 = []\n","        x_batch2 = []\n","        y_batch = []\n","        \n","        for idd in range(i,min(i+ batch_size,num_test)):\n","                # seq = get_seq()  \n","            imgf = data_face[idd]\n","            imgfa = data_face_asl[idd]\n","            imgr = data_road[idd]\n","            imgra = data_road_asl[idd]\n","            \n","\n","            if labels[idd]==0 :#or y[idd]==1 or y[idd]==3 :\n","                \n","                  x_batch.append(imgf[0:30:2])\n","                  x_batch1.append(imgr[0:30:2] )\n","                  x_batch2.append(imgfa[0:30:2])\n","                  x_batch3.append(imgra [0:30:2])\n","\n","\n","                  y_batch.append(labels[idd])\n","            else:\n","                  a,b,c,d,e= data_augmentation_tempen(imgf[0:30:2],imgr[0:30:2],imgfa[0:30:2],imgra [0:30:2], labels[idd])\n","                  # a,b,c,d,e= data_augmentation_tempen(imgf,imgr,imgfa,imgra, y[idd])\n","\n","                  x_batch.append(a)\n","                  x_batch1.append(b)\n","                  x_batch2.append(c)\n","                  x_batch3.append(d)\n","                  y_batch.append(e)\n","\n","\n","\n","        x_batch  = np.array(x_batch).reshape((-1,128,384)) /255\n","        x_batch1 = np.array(x_batch1).reshape((-1,128,384))/255\n","\n","        x_batch2 = np.array(x_batch2).reshape((-1,128,128,3))/255\n","        x_batch3 = np.array(x_batch3).reshape((-1,128,128,3))/255\n","        image_1 = [x_batch3,x_batch1,x_batch2,x_batch]\n","        y_batch = np.array(y_batch)\n","        y_batch = to_categorical(y_batch,5)\n","\n","        features  = modela(image_1, training=False)\n","        logitsb = modelb(features , training=False)\n","\n","        accuracyb = st_accb(tf.math.argmax(y_batch,axis=1), tf.math.argmax(logitsb,axis=1))\n","        loss += CCLoss(y_batch, logitsb).numpy()\n","\n","    loss /= int(65/batch_size)\n","    accuracyb = accuracyb.numpy()\n","    return loss,accuracyb"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class EstimatorCV():\n","    def __init__(self, feature_num, class_num):\n","        super(EstimatorCV, self).__init__()\n","        self.class_num = class_num\n","        self.CoVariance = np.zeros((class_num, feature_num, feature_num))\n","        self.Ave = np.zeros((feature_num, class_num))\n","        self.Amount = np.zeros((class_num))\n","\n","    def update_CV(self, features, labels):\n","        N = features.shape[0]\n","        C = self.class_num\n","        A = features.shape[1]\n","\n","        # NxCxFeatures = features.reshape(N, 1, A).expand(N, C, A)\n","        # NxCxFeatures = np.broadcast_to(features.reshape((N, 1, A)),(N, C, A))\n","        NxCxFeatures = np.broadcast_to(features.reshape((N, A, 1)),(N, A, C))\n","\n","\n","        onehot = np.zeros((N, C))\n","        # onehot.scatter_(1, labels.reshape((-1, 1)), 1)#####\n","        onehot = scatter_numpy(onehot, 1, labels.reshape((-1, 1)), 1)\n","\n","        # NxCxA_onehot = np.broadcast_to(onehot.reshape((N, C, 1)),(N, C, A))####\n","        NxCxA_onehot = np.broadcast_to(onehot.reshape((N, 1, C)),(N, A, C))####\n","\n","\n","\n","        features_by_sort = np.multiply(NxCxFeatures,NxCxA_onehot)\n","        \n","\n","        Amount_CxA = np.sum(NxCxA_onehot,axis=0)#NxCxA_onehot.sum(0)\n","        Amount_CxA[Amount_CxA == 0] = 1\n","\n","        ave_CxA =  np.sum(features_by_sort,axis=0) / Amount_CxA#features_by_sort.sum(0) / Amount_CxA\n","\n","        var_temp = features_by_sort -  np.multiply(np.broadcast_to(ave_CxA,(N, A, C)),NxCxA_onehot) ##\n","\n","        \n","\n","\n","\n","        var_temp = np.divide(np.transpose(var_temp,(2, 1, 0))@ np.transpose(var_temp,(2, 0, 1)),np.broadcast_to(Amount_CxA.reshape((C, A, 1)),(C, A, A)))\n","\n","        # sum_weight_CV = onehot.sum(0).view(C, 1, 1).expand(C, A, A)\n","        sum_weight_CV = np.broadcast_to(np.sum(onehot,axis=0).reshape((C, 1, 1)),(C, A, A))\n","\n","\n","        # sum_weight_AV = onehot.sum(0).view(C, 1).expand(C, A)\n","        sum_weight_AV = np.broadcast_to(np.sum(onehot,axis=0).reshape((C, 1)),(C, A))\n","\n","\n","        weight_CV = np.broadcast_to(np.divide(sum_weight_CV,sum_weight_CV + self.Amount.reshape((C, 1, 1))),(C, A, A)).copy()#.setflags(write=1)#.copy().fill(5.446361E-01)#\n","       \n","        \n","        \n","        weight_CV[weight_CV != weight_CV] = 0\n","        \n","\n","        weight_AV = np.broadcast_to(np.divide(sum_weight_AV,sum_weight_AV + self.Amount.reshape((C, 1))),(C, A)).copy()#.setflags(write=1)####\n","        weight_AV[np.where(weight_AV != weight_AV)[0]] = 0\n","\n","      \n","\n","        additional_CV = np.multiply(np.multiply(weight_CV,(1 - weight_CV)),((self.Ave - ave_CxA).reshape((C, A, 1))@(self.Ave - ave_CxA).reshape((C, 1, A))))####\n","\n","        self.CoVariance = (np.multiply(self.CoVariance,(1 - weight_CV)) + \n","                      np.multiply(var_temp,weight_CV)) + additional_CV\n","       \n","\n","\n","\n","\n","        self.Ave = (np.multiply(self.Ave,(1 - weight_AV.reshape((A,  C)))) + np.multiply(ave_CxA,weight_AV.reshape((A,  C))))\n","        self.Amount += np.sum(onehot,axis=0)\n","\n","\n","class ISDALoss():\n","    def __init__(self, feature_num, class_num):\n","        super(ISDALoss, self).__init__()\n","\n","        self.estimator = EstimatorCV(feature_num, class_num)\n","\n","        self.class_num = class_num\n","\n","        self.cross_entropy = tf.keras.losses.CategoricalCrossentropy()\n","\n","    def isda_aug(self, fc, features, y, labels, cv_matrix, ratio):\n","\n","        N = features.shape[0]\n","        C = self.class_num\n","        A = features.shape[1]\n","        # C = features.shape[1]#self.class_num\n","        # A = self.class_num# features.shape[1]\n","\n","        weight_m = list(fc.get_weights())[0]\n","\n","        # print(weight_m.shape)\n","\n","        # NxW_ij = np.broadcast_to(weight_m,(N, C, A)).copy()\n","        NxW_ij = np.broadcast_to(weight_m,(N, A, C)).copy()\n","\n","\n","        # NxW_kj = gather_numpy(NxW_ij, 1, np.broadcast_to(labels.reshape(N, 1, 1),(N, C, A)).copy())\n","        NxW_kj = gather_numpy(NxW_ij, 2, np.broadcast_to(labels.reshape(N, 1, 1),(N, A, C)).copy())\n","\n","\n","        CV_temp = cv_matrix[labels]\n","\n","        # sigma2 = ratio * \\\n","        #          torch.bmm(torch.bmm(NxW_ij - NxW_kj,\n","        #                              CV_temp).view(N * C, 1, A),\n","        #                    (NxW_ij - NxW_kj).view(N * C, A, 1)).view(N, C)\n","        # print(NxW_ij.shape) # (2, 512, 5)\n","        # print(NxW_kj.shape) # (2, 512, 5)\n","        # # print(((NxW_ij - NxW_kj)@CV_temp).shape)\n","        # print(CV_temp.shape) #    (2, 5, 512)@  (2, 512, 512)\n","        # # print(CV_temp.shape)3\n","        # print((np.transpose((NxW_ij - NxW_kj),(0, 2, 1))@CV_temp).shape) # (2, 5, 512)\n","        \n","        # print(np.transpose((NxW_ij - NxW_kj),(0, 2, 1)).shape)# (2, 5, 512)  (2, 512, 5)\n","\n","        sigma2 = ratio * ((np.transpose((NxW_ij - NxW_kj),(0, 2, 1))@CV_temp)@ (NxW_ij - NxW_kj))\n","\n","\n","        # sigma2 = ratio * (((NxW_ij - NxW_kj)@CV_temp)@ np.transpose((NxW_ij - NxW_kj),(0, 2, 1)))\n","\n","        sigma2 = np.sum(np.multiply(sigma2,np.broadcast_to(np.eye((C)),(N, C, C)).copy()),axis=2).reshape((N, C))\n","\n","        aug_result = y + 0.5 * sigma2\n","\n","        return aug_result\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def scatter_numpy(data, dim, index, src):\n","    \"\"\"\n","    Writes all values from the Tensor src into self at the indices specified in the index Tensor.\n","\n","    :param dim: The axis along which to index\n","    :param index: The indices of elements to scatter\n","    :param src: The source element(s) to scatter\n","    :return: self\n","    \"\"\"\n","    if index.dtype != np.dtype('int_'):\n","        raise TypeError(\"The values of index must be integers\")\n","    if data.ndim != index.ndim:\n","        raise ValueError(\"Index should have the same number of dimensions as output\")\n","    if dim >= data.ndim or dim < -data.ndim:\n","        raise IndexError(\"dim is out of range\")\n","    if dim < 0:\n","        # Not sure why scatter should accept dim < 0, but that is the behavior in PyTorch's scatter\n","        dim = data.ndim + dim\n","    idx_xsection_shape = index.shape[:dim] + index.shape[dim + 1:]\n","    self_xsection_shape = data.shape[:dim] + data.shape[dim + 1:]\n","    if idx_xsection_shape != self_xsection_shape:\n","        raise ValueError(\"Except for dimension \" + str(dim) +\n","                         \", all dimensions of index and output should be the same size\")\n","    if (index >= data.shape[dim]).any() or (index < 0).any():\n","        raise IndexError(\"The values of index must be between 0 and (self.shape[dim] -1)\")\n","\n","    def make_slice(arr, dim, i):\n","        slc = [slice(None)] * arr.ndim\n","        slc[dim] = i\n","        return slc\n","\n","    # We use index and dim parameters to create idx\n","    # idx is in a form that can be used as a NumPy advanced index for scattering of src param. in self\n","    idx = [[*np.indices(idx_xsection_shape).reshape(index.ndim - 1, -1),\n","            index[make_slice(index, dim, i)].reshape(1, -1)[0]] for i in range(index.shape[dim])]\n","    idx = list(np.concatenate(idx, axis=1))\n","    idx.insert(dim, idx.pop())\n","\n","    if not np.isscalar(src):\n","        if index.shape[dim] > src.shape[dim]:\n","            raise IndexError(\"Dimension \" + str(dim) + \"of index can not be bigger than that of src \")\n","        src_xsection_shape = src.shape[:dim] + src.shape[dim + 1:]\n","        if idx_xsection_shape != src_xsection_shape:\n","            raise ValueError(\"Except for dimension \" +\n","                             str(dim) + \", all dimensions of index and src should be the same size\")\n","        # src_idx is a NumPy advanced index for indexing of elements in the src\n","        src_idx = list(idx)\n","        src_idx.pop(dim)\n","        src_idx.insert(dim, np.repeat(np.arange(index.shape[dim]), np.prod(idx_xsection_shape)))\n","        data[idx] = src[src_idx]\n","\n","    else:\n","        data[idx] = src\n","\n","    return data\n","\n","\n","def gather_numpy(data, dim, index):\n","    \"\"\"\n","    Gathers values along an axis specified by dim.\n","    For a 3-D tensor the output is specified by:\n","        out[i][j][k] = input[index[i][j][k]][j][k]  # if dim == 0\n","        out[i][j][k] = input[i][index[i][j][k]][k]  # if dim == 1\n","        out[i][j][k] = input[i][j][index[i][j][k]]  # if dim == 2\n","\n","    :param dim: The axis along which to index\n","    :param index: A tensor of indices of elements to gather\n","    :return: tensor of gathered values\n","    \"\"\"\n","    idx_xsection_shape = index.shape[:dim] + index.shape[dim + 1:]\n","    self_xsection_shape = data.shape[:dim] + data.shape[dim + 1:]\n","    if idx_xsection_shape != self_xsection_shape:\n","        raise ValueError(\"Except for dimension \" + str(dim) +\n","                         \", all dimensions of index and self should be the same size\")\n","    if index.dtype != np.dtype('int_'):\n","        raise TypeError(\"The values of index must be integers\")\n","    data_swaped = np.swapaxes(data, 0, dim)\n","    index_swaped = np.swapaxes(index, 0, dim)\n","    # print(index_swaped.shape)\n","    # print(data_swaped.shape)\n","\n","    gathered = np.choose(index_swaped, data_swaped)\n","    return np.swapaxes(gathered, 0, dim)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from PIL import Image\n","from PIL import ImageOps\n","IMAGE_SIZE = 128\n","\n","def int_parameter(level, maxval):\n","    return int(level * maxval / 10)\n","\n","\n","def float_parameter(level, maxval):\n","    return float(level) * maxval / 10.\n","\n","\n","def sample_level(n):\n","    return np.random.uniform(low=0.1, high=n)\n","\n","\n","def autocontrast(pil_img, _):\n","    return ImageOps.autocontrast(pil_img)\n","\n","\n","def equalize(pil_img, _):\n","    return ImageOps.equalize(pil_img)\n","\n","\n","def posterize(pil_img, level):\n","    level = int_parameter(sample_level(level), 4)\n","    return ImageOps.posterize(pil_img, 4 - level)\n","\n","\n","def rotate(pil_img, level):\n","    degrees = int_parameter(sample_level(level), 30)\n","    if np.random.uniform() > 0.5:\n","        degrees = -degrees\n","    return pil_img.rotate(degrees, resample=Image.BILINEAR)\n","\n","\n","def solarize(pil_img, level):\n","    level = int_parameter(sample_level(level), 256)\n","    return ImageOps.solarize(pil_img, 256 - level)\n","\n","\n","def shear_x(pil_img, level):\n","    level = float_parameter(sample_level(level), 0.3)\n","    if np.random.uniform() > 0.5:\n","        level = -level\n","    return pil_img.transform((IMAGE_SIZE, IMAGE_SIZE),\n","                            Image.AFFINE, (1, level, 0, 0, 1, 0),\n","                            resample=Image.BILINEAR)\n","\n","\n","def shear_y(pil_img, level):\n","    level = float_parameter(sample_level(level), 0.3)\n","    if np.random.uniform() > 0.5:\n","        level = -level\n","    return pil_img.transform((IMAGE_SIZE, IMAGE_SIZE),\n","                            Image.AFFINE, (1, 0, 0, level, 1, 0),\n","                            resample=Image.BILINEAR)\n","\n","\n","def translate_x(pil_img, level):\n","    level = int_parameter(sample_level(level), IMAGE_SIZE / 3)\n","    if np.random.random() > 0.5:\n","        level = -level\n","    return pil_img.transform((IMAGE_SIZE, IMAGE_SIZE),\n","                            Image.AFFINE, (1, 0, level, 0, 1, 0),\n","                            resample=Image.BILINEAR)\n","\n","\n","def translate_y(pil_img, level):\n","    level = int_parameter(sample_level(level), IMAGE_SIZE / 3)\n","    if np.random.random() > 0.5:\n","        level = -level\n","    return pil_img.transform((IMAGE_SIZE, IMAGE_SIZE),\n","                            Image.AFFINE, (1, 0, 0, 0, 1, level),\n","                            resample=Image.BILINEAR)\n","    \n","augmentations = [autocontrast, \n","                  equalize, \n","                  posterize, \n","                  solarize]\n","\n","\n","def apply_op(image, op, severity):\n","    image = np.clip(image * 255., 0, 255).astype(np.uint8)\n","    pil_img = Image.fromarray(image)  \n","    pil_img = op(pil_img, severity)\n","    return np.asarray(pil_img).astype(np.float32) \n","\n","\n","def augment_and_mix( image, severity=3, width=3, depth=-1, alpha=1.):\n","\n","    ws = np.random.dirichlet([alpha] * width).astype(np.float32)\n","    m  = np.float32(np.random.beta(alpha, alpha))\n","    mix = np.zeros_like(image).astype(np.float32)\n","\n","    for i in range(width):\n","        image_aug = image.copy()\n","        depth = depth if depth > 0 else np.random.randint(1, 3)\n","        for _ in range(depth):\n","            op = np.random.choice(augmentations)\n","            image_aug = apply_op(image_aug, op, severity)\n","           \n","            mix += ws[i] * image_aug\n","\n","    \n","    mixed = (1 - m)*image + m*mix\n","    return mixed\n","\n","\n","def apply_augment(data,udata,dual=True):\n","    \n","    batch_len = len(data)  \n","    X_orig = np.zeros((batch_len, 128,128,3), dtype=np.float32)\n","    \n","    \n","    if dual:\n","        X_aug1 = np.zeros_like(X_orig, dtype=np.float32)\n","        X_aug2 = np.zeros_like(X_orig, dtype=np.float32)\n","        # X_aug3 = np.zeros_like(X_orig, dtype=np.float32)\n","    for  index in range(batch_len):\n","        img = data[index]\n","        uimg = udata[index]\n","        \n","        if dual:\n","            X_aug1[index] = augment_and_mix(uimg)\n","            X_aug2[index] = augment_and_mix(img)\n","            # X_orig[index] = augment_and_mix(img)\n","        else:\n","            X_orig[index] = augment_and_mix(img)\n","       \n","    \n","    if not dual:\n","        return X_orig\n","    else:\n","        return  X_aug1, X_aug2"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import time\n","num_train_data = 364\n","batch_size = 5\n","num_epoch = 160\n","num_test = 455\n","trainphase = True\n","modela = define_model((30,128,256,3))\n","modelb = define_modelfc((30,128,256,3))\n","\n","# modela = tf.keras.models.load_model('/content/drive/MyDrive/Modelat.h5') \n","# modelb = tf.keras.models.load_model('/content/drive/MyDrive/Modelbt.h5')\n","\n","def step_decay(epoch):\n","     \n","     initAlpha = 0.0003\n","     factor = .89\n","     dropEvery = 39\n","     alpha = initAlpha * (factor ** np.floor((1 + epoch) / dropEvery))\n","     return float(alpha)\n","\n","input_shape = [(None,128, 128, 3),(None,128, 384),(None,128, 128, 3),(None,128, 384)]\n","input_shape = [(None,2048)]\n","\n","\n","modela.build(input_shape)    \n","modelb.build(input_shape) \n","\n","CCLoss = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.25)   \n","CCLoss1 = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.25)  \n","loss_object = tf.keras.losses.MeanSquaredError()\n","isda = ISDALoss(int(2048), 5)\n","\n","\n","optimizer = Adam(lr=0.0003, beta_1=0.9, beta_2=0.999, epsilon=None, amsgrad=False)\n","iStep = 0 \n","print('Training beginning')\n","total_epoch_loss = []\n","\n","total_test_acc =[]\n","tmp =0\n","tmpb =0\n","tmpa =0\n","for epoch in range(num_epoch):\n","    epoch_loss = 0 # total epoch loss\n","\n","    t1 = int(time.time())\n","    \n","    for i in range(0, num_train_data, batch_size):\n","        x_batch = []\n","        x_batch1 = []\n","        x_batch3 = []\n","        x_batch2 = []\n","        y_batch = []\n","        \n","        for idd in range(i,min(i + batch_size,num_train_data)):\n","              \n","            imgf = data_face[idd]\n","            imgfa = data_face_asl[idd]\n","            imgr = data_road[idd]\n","            imgra = data_road_asl[idd]\n","            \n","            if np.random.uniform() > 0.5:\n","               imgfa,imgra = apply_augment(imgfa,imgra)\n","            \n","            if np.random.uniform() > 0.5:\n","              imgfa = augment_cutout(imgfa).numpy()\n","              # imgra = augment_cutout(imgra).numpy()\n","            if np.random.uniform() > 0.5:\n","              # imgfa = augment_cutout(imgfa).numpy()\n","              imgra = augment_cutout(imgra).numpy()\n","          \n","\n","            if labels[idd]==0 :#or y[idd]==1 or y[idd]==3 :\n","                \n","                  x_batch.append(imgf[0:30:2])\n","                  x_batch1.append(imgr[0:30:2] )\n","                  x_batch2.append(imgfa[0:30:2])\n","                  x_batch3.append(imgra [0:30:2])\n","                  # x_batch.append(imgf)\n","                  # x_batch1.append(imgr )\n","                  # x_batch2.append(imgfa)\n","                  # x_batch3.append( imgra )\n","\n","                  y_batch.append(labels[idd])\n","            else:\n","                  if np.random.uniform() > 0.5:\n","                    a,b,c,d,e= data_augmentation_tempen(imgf[0:30:2],imgr[0:30:2],imgfa[0:30:2],imgra [0:30:2], labels[idd])\n","                    # a,b,c,d,e= data_augmentation_tempen(imgf,imgr,imgfa,imgra, y[idd])\n","\n","                    x_batch.append(a)\n","                    x_batch1.append(b)\n","                    x_batch2.append(c)\n","                    x_batch3.append(d)\n","                    y_batch.append(e)\n","                  else:\n","                    a,b,c,d,e= data_augmentation_tempen(imgf[1:30:2],imgr[1:30:2],imgfa[1:30:2],imgra [1:30:2], labels[idd])\n","                    \n","                    x_batch.append(a)\n","                    x_batch1.append(b)\n","                    x_batch2.append(c)\n","                    x_batch3.append(d)\n","                    y_batch.append(e)\n","\n","\n","\n","        x_batch  = np.array(x_batch).reshape((-1,128,384)) /255\n","        x_batch1 = np.array(x_batch1).reshape((-1,128,384))/255\n","\n","        x_batch2 = np.array(x_batch2).reshape((-1,128,128,3))/255\n","        x_batch3 = np.array(x_batch3).reshape((-1,128,128,3))/255\n","\n","        y_batch = np.array(y_batch)\n","        y_batch = to_categorical(y_batch,5)\n","\n","\n","       \n","\n","\n","\n","        lr = step_decay(epoch)\n","        optimizer.learning_rate.assign(lr)\n","\n","        image_1 = [x_batch3,x_batch1,x_batch2,x_batch]\n","        trainphase = True\n","\n","        total_loss = train_step(image_1,image_1, y_batch,epoch)\n","\n","        epoch_loss       += total_loss.numpy()\n","\n","    epoch_loss       /= int(num_train_data/batch_size) # calc mean of epoch loss\n","   \n","\n","    total_epoch_loss.append(epoch_loss)\n","    trainphase = False\n","    Te_test_loss,accuracyb = evaluate()\n","\n","    if tmpb<accuracyb:\n","      tmpb = accuracyb\n","      t2 = int(time.time())\n","      modela.save('./Modela.h5')\n","      modelb.save('./Modelfc.h5')\n","      message = f\"Epoch {epoch+1}/{num_epoch} Done: BAcc: {tmpb:.3f} | t: {t2-t1} sec\"\n","      print(message)\n","    else:\n","      message = f\"Epoch {epoch+1}/{num_epoch} Done: max Acc: {tmpb:.3f} |\"\n","      print(message)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
